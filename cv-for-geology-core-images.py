"""–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≥–æ—Ä–Ω—ã—Ö –ø–æ—Ä–æ–¥ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –∫–µ—Ä–Ω–∞

–ú–æ–¥–µ–ª—å –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–∏–ø–æ–≤ –≥–æ—Ä–Ω—ã—Ö –ø–æ—Ä–æ–¥
–ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –∫–µ—Ä–Ω–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π.
"""

# =============================================================================
# –ò–ú–ü–û–†–¢ –ë–ò–ë–õ–ò–û–¢–ï–ö –ò –°–û–ó–î–ê–ù–ò–ï –ü–ê–ü–û–ö
# =============================================================================
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision import models
import pandas as pd
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import os
import json
import joblib
from pathlib import Path

# –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
print("üìÅ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫...")
folders = ['images', 'results', 'models', 'data']
for folder in folders:
    if not os.path.exists(folder):
        os.makedirs(folder)
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞: {folder}/")

# =============================================================================
# –ó–ê–ì–†–£–ó–ö–ê –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•
# =============================================================================
print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ kagglehub –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
import subprocess
import sys
def install_package(package):
    try:
        __import__(package)
    except ImportError:
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])

install_package('kagglehub')

import kagglehub

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
path = kagglehub.dataset_download("stealthtechnologies/rock-classification")
print(f'üì¶ –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –≤: {path}')

# –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
print("üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö...")

def analyze_dataset(path):
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    total_images = len(list(Path(path).rglob('*.jpg'))) + len(list(Path(path).rglob('*.png')))
    folders = {}

    for p in Path(path).rglob('*.jpg'):
        folder_name = p.parent.name
        folders[folder_name] = folders.get(folder_name, 0) + 1

    print(f"üìä –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images}")
    print(f"üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫: {folders}")

    return total_images, folders

total_images, folder_structure = analyze_dataset(path)

# –°–±–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
print("\nüì• –°–±–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")

metadata = []

def collect_images_from_folder(folder_path, data_type):
    images = []
    if os.path.exists(folder_path):
        for class_name in os.listdir(folder_path):
            class_path = os.path.join(folder_path, class_name)

            if os.path.isdir(class_path):
                class_images = []
                for file in os.listdir(class_path):
                    if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                        full_path = os.path.join(class_path, file)
                        class_images.append(full_path)

                        metadata.append({
                            'file_path': full_path,
                            'class_name': class_name,
                            'data_type': data_type
                        })

                print(f"   üéØ {class_name}: {len(class_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                images.extend(class_images)
    return images

rock_data_path = os.path.join(path, 'Rock Data')
data_types = ['train', 'test', 'valid']

train_images, test_images, valid_images = [], [], []

for data_type in data_types:
    folder = os.path.join(rock_data_path, data_type)
    if data_type == 'train':
        train_images = collect_images_from_folder(folder, data_type)
    elif data_type == 'test':
        test_images = collect_images_from_folder(folder, data_type)
    elif data_type == 'valid':
        valid_images = collect_images_from_folder(folder, data_type)

print(f"\n‚úÖ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
print(f"   üèãÔ∏è  –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(train_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
print(f"   üß™ –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(test_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
print(f"   üìä –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(valid_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
print(f"   üìà –í—Å–µ–≥–æ: {len(metadata)} –∑–∞–ø–∏—Å–µ–π –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")

# =============================================================================
# –°–û–ó–î–ê–ù–ò–ï DATASET –ò DATALOADER
# =============================================================================
class RockDataset(Dataset):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π Dataset –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≥–æ—Ä–Ω—ã—Ö –ø–æ—Ä–æ–¥"""

    def __init__(self, metadata_list, transform=None):
        self.metadata = metadata_list
        self.transform = transform

        self.classes = sorted(list(set([item['class_name'] for item in metadata_list])))
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}
        self.idx_to_class = {idx: cls for cls, idx in self.class_to_idx.items()}

    def __len__(self):
        return len(self.metadata)

    def __getitem__(self, idx):
        item = self.metadata[idx]
        file_path = item['file_path']
        class_name = item['class_name']

        image = Image.open(file_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        label = self.class_to_idx[class_name]
        return image, label

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
train_metadata = [item for item in metadata if item['data_type'] == 'train']
test_metadata = [item for item in metadata if item['data_type'] == 'test']
valid_metadata = [item for item in metadata if item['data_type'] == 'valid']

# –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

basic_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# –°–æ–∑–¥–∞–Ω–∏–µ datasets –∏ dataloaders
train_dataset = RockDataset(train_metadata, transform=train_transform)
valid_dataset = RockDataset(valid_metadata, transform=basic_transform)
test_dataset = RockDataset(test_metadata, transform=basic_transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)

print(f"\nüì¶ Datasets —Å–æ–∑–¥–∞–Ω—ã:")
print(f"   üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {len(train_dataset.classes)}")
print(f"   üìù –ö–ª–∞—Å—Å—ã: {train_dataset.classes}")

# =============================================================================
# –°–û–ó–î–ê–ù–ò–ï –ò –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô
# =============================================================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üì± –ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

def create_rock_classifier(num_classes):
    """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≥–æ—Ä–Ω—ã—Ö –ø–æ—Ä–æ–¥"""
    model = models.resnet18(pretrained=True)

    # –ó–∞–º–æ—Ä–æ–∑–∫–∞ –≤–µ—Å–æ–≤
    for param in model.parameters():
        param.requires_grad = False

    # –ó–∞–º–µ–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è
    model.fc = nn.Linear(model.fc.in_features, num_classes)

    # –†–∞–∑–º–æ—Ä–æ–∑–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è
    for param in model.fc.parameters():
        param.requires_grad = True

    return model

# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
model = create_rock_classifier(num_classes=len(train_dataset.classes))
model = model.to(device)

print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞!")
print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {len(train_dataset.classes)}")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—É—á–µ–Ω–∏—è
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, epochs=10):
    """–§—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""
    train_losses = []
    valid_accuracies = []
    best_accuracy = 0.0

    print("üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")

    for epoch in range(epochs):
        # –û–±—É—á–µ–Ω–∏–µ
        model.train()
        running_loss = 0.0

        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        correct = 0
        total = 0

        with torch.no_grad():
            for images, labels in valid_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        # –ú–µ—Ç—Ä–∏–∫–∏
        train_loss = running_loss / len(train_loader)
        accuracy = 100 * correct / total

        train_losses.append(train_loss)
        valid_accuracies.append(accuracy)

        scheduler.step()

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            torch.save(model.state_dict(), 'models/best_rock_model.pth')

        print(f'Epoch [{epoch+1}/{epochs}], '
              f'Loss: {train_loss:.4f}, '
              f'Accuracy: {accuracy:.2f}%, '
              f'Best: {best_accuracy:.2f}%')

    return train_losses, valid_accuracies

# –û–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
print("üéØ –û–±—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
train_losses, valid_accuracies = train_model(
    model=model,
    train_loader=train_loader,
    valid_loader=valid_loader,
    criterion=criterion,
    optimizer=optimizer,
    scheduler=scheduler,
    epochs=10
)

# =============================================================================
# –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò –û–¶–ï–ù–ö–ê
# =============================================================================
print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

# –ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
model.load_state_dict(torch.load('models/best_rock_model.pth'))
model.eval()

test_correct = 0
test_total = 0

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        test_total += labels.size(0)
        test_correct += (predicted == labels).sum().item()

test_accuracy = 100 * test_correct / test_total
print(f"‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {test_accuracy:.2f}%")

# =============================================================================
# –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ú–û–î–ï–õ–¨ –° FINE-TUNING
# =============================================================================
print("\nüîß –°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å fine-tuning...")

def create_improved_model(num_classes):
    """–°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å —Ä–∞–∑–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º–∏ —Å–ª–æ—è–º–∏"""
    model = models.resnet18(pretrained=True)

    # –ó–∞–º–æ—Ä–æ–∑–∫–∞ –≤—Å–µ—Ö —Å–ª–æ–µ–≤
    for param in model.parameters():
        param.requires_grad = False

    # –†–∞–∑–º–æ—Ä–æ–∑–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–ª–æ–µ–≤
    for name, param in model.named_parameters():
        if 'layer3' in name or 'layer4' in name or 'fc' in name:
            param.requires_grad = True

    # –£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    model.fc = nn.Sequential(
        nn.Dropout(0.5),
        nn.Linear(model.fc.in_features, 512),
        nn.ReLU(),
        nn.Dropout(0.3),
        nn.Linear(512, num_classes)
    )

    return model

# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
model_improved = create_improved_model(len(train_dataset.classes))
model_improved = model_improved.to(device)

# –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å —Ä–∞–∑–Ω—ã–º–∏ learning rates
optimizer_improved = torch.optim.Adam([
    {'params': model_improved.layer3.parameters(), 'lr': 0.0001},
    {'params': model_improved.layer4.parameters(), 'lr': 0.0001},
    {'params': model_improved.fc.parameters(), 'lr': 0.001}
])

print("üöÄ –û–±—É—á–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
train_losses_improved, valid_accuracies_improved = train_model(
    model=model_improved,
    train_loader=train_loader,
    valid_loader=valid_loader,
    criterion=criterion,
    optimizer=optimizer_improved,
    scheduler=scheduler,
    epochs=15
)

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
model_improved.load_state_dict(torch.load('models/best_rock_model.pth'))
model_improved.eval()

test_correct_improved = 0
test_total_improved = 0

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model_improved(images)
        _, predicted = torch.max(outputs.data, 1)
        test_total_improved += labels.size(0)
        test_correct_improved += (predicted == labels).sum().item()

test_accuracy_improved = 100 * test_correct_improved / test_total_improved
print(f"‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {test_accuracy_improved:.2f}%")

# =============================================================================
# –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
# =============================================================================
print("\nüìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

plt.figure(figsize=(15, 5))

# –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
plt.subplot(1, 3, 1)
plt.plot(train_losses, 'b-', label='–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å', linewidth=2)
plt.plot(train_losses_improved, 'r-', label='–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å', linewidth=2)
plt.title('–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è')
plt.xlabel('–≠–ø–æ—Ö–∞')
plt.ylabel('–ü–æ—Ç–µ—Ä–∏')
plt.legend()
plt.grid(True)

# –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
plt.subplot(1, 3, 2)
plt.plot(valid_accuracies, 'b-', label='–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å', linewidth=2)
plt.plot(valid_accuracies_improved, 'r-', label='–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å', linewidth=2)
plt.title('–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ')
plt.xlabel('–≠–ø–æ—Ö–∞')
plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å (%)')
plt.legend()
plt.grid(True)

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
plt.subplot(1, 3, 3)
models_names = ['–ë–∞–∑–æ–≤–∞—è\n–º–æ–¥–µ–ª—å', '–£–ª—É—á—à–µ–Ω–Ω–∞—è\n–º–æ–¥–µ–ª—å']
accuracies = [test_accuracy, test_accuracy_improved]
colors = ['blue', 'red']

bars = plt.bar(models_names, accuracies, color=colors, alpha=0.7)
plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π')
plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ (%)')
plt.ylim(0, 100)

for bar, acc in zip(bars, accuracies):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
             f'{acc:.1f}%', ha='center', va='bottom')

plt.tight_layout()
plt.savefig('images/training_results.png', dpi=300, bbox_inches='tight')
plt.show()

# =============================================================================
# –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
# =============================================================================
print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
results = {
    'basic_model_accuracy': test_accuracy,
    'improved_model_accuracy': test_accuracy_improved,
    'improvement': test_accuracy_improved - test_accuracy,
    'num_classes': len(train_dataset.classes),
    'class_names': train_dataset.classes,
    'dataset_stats': {
        'train_images': len(train_images),
        'test_images': len(test_images),
        'valid_images': len(valid_images),
        'total_images': total_images
    }
}

with open('results/training_results.json', 'w', encoding='utf-8') as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
model_info = {
    'best_model_path': 'models/best_rock_model.pth',
    'input_size': 224,
    'num_classes': len(train_dataset.classes),
    'class_mapping': train_dataset.class_to_idx,
    'transform_info': {
        'mean': [0.485, 0.456, 0.406],
        'std': [0.229, 0.224, 0.225]
    }
}

with open('results/model_info.json', 'w', encoding='utf-8') as f:
    json.dump(model_info, f, ensure_ascii=False, indent=2)

print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
print("   üìä results/training_results.json - –º–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è")
print("   üîß results/model_info.json - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏")
print("   üñºÔ∏è  images/training_results.png - –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è")

# =============================================================================
# –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢
# =============================================================================
print("\n" + "="*60)
print("üéâ –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–†–û–ï–ö–¢–ê")
print("="*60)

print(f"üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: –£–ª—É—á—à–µ–Ω–Ω–∞—è ResNet18")
print(f"üìä –ú–µ—Ç—Ä–∏–∫–∏:")
print(f"   ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {test_accuracy:.2f}%")
print(f"   ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {test_accuracy_improved:.2f}%")
print(f"   ‚Ä¢ –£–ª—É—á—à–µ–Ω–∏–µ: {test_accuracy_improved - test_accuracy:+.2f}%")

print(f"\nüìÅ –î–∞–Ω–Ω—ã–µ:")
print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {len(train_dataset.classes)}")
print(f"   ‚Ä¢ –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(train_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
print(f"   ‚Ä¢ –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(test_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
print(f"   ‚Ä¢ –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images}")

print(f"\nüîß –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:")
print(f"   ‚Ä¢ Transfer learning —Å ResNet18")
print(f"   ‚Ä¢ Fine-tuning –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–ª–æ–µ–≤")
print(f"   ‚Ä¢ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±–æ–±—â–µ–Ω–∏—è")
print(f"   ‚Ä¢ –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º")

print(f"\nüìÅ –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê:")
print("   rock-classification-cv/")
print("   ‚îú‚îÄ‚îÄ rock_classification.py     # –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç")
print("   ‚îú‚îÄ‚îÄ requirements.txt          # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")
print("   ‚îú‚îÄ‚îÄ README.md                 # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è")
print("   ‚îú‚îÄ‚îÄ models/                   # –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏")
print("   ‚îú‚îÄ‚îÄ results/                  # –ú–µ—Ç—Ä–∏–∫–∏ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
print("   ‚îú‚îÄ‚îÄ images/                   # –ì—Ä–∞—Ñ–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
print("   ‚îî‚îÄ‚îÄ data/                     # –î–∞–Ω–Ω—ã–µ (–∞–≤—Ç–æ–∑–∞–≥—Ä—É–∑–∫–∞)")

print("\n‚úÖ –ü–†–û–ï–ö–¢ –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
